{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8nqZ340NRf/Z5Yd/oJ3v9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PGFDEE/Assignment1/blob/main/Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3HYBugnPgcY",
        "outputId": "f4332bc2-548a-4baf-89eb-9c0b9930cf15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual loop: Best k = 13, Mean CV Accuracy = 0.9800\n",
            "GridSearchCV: Best k = 13, Mean CV Accuracy = 0.9800\n",
            "Do they match? Yes\n",
            "Confirmed: k=13 is the optimal parameter with cv=10.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "\n",
        "# 1) Load the Iris dataset\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "\n",
        "\n",
        "# 2) Evaluate k = 1..31 using cv=10 (10-fold cross-validation)\n",
        "\n",
        "# Use range(1, 32) to include 31\n",
        "\n",
        "k_range = range(1, 32)\n",
        "\n",
        "mean_accuracies = []\n",
        "\n",
        "std_accuracies = []\n",
        "\n",
        "\n",
        "\n",
        "for k in k_range:\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')  # cv=10 directly\n",
        "\n",
        "    mean_accuracies.append(scores.mean())\n",
        "\n",
        "    std_accuracies.append(scores.std())\n",
        "\n",
        "\n",
        "\n",
        "# Determine optimal k from the manual loop\n",
        "\n",
        "best_k_manual = k_range[np.argmax(mean_accuracies)]\n",
        "\n",
        "best_acc_manual = max(mean_accuracies)\n",
        "\n",
        "print(f\"Manual loop: Best k = {best_k_manual}, Mean CV Accuracy = {best_acc_manual:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# 3) Plot 1: Mean accuracy vs k (save as knn-1.jpg)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(list(k_range), mean_accuracies, marker='o')\n",
        "\n",
        "plt.title('Value of K for KNN vs Cross-Validated Accuracy')\n",
        "\n",
        "plt.xlabel('Value of K for KNN')\n",
        "\n",
        "plt.ylabel('Cross-Validated Accuracy')\n",
        "\n",
        "plt.grid(True)\n",
        "\n",
        "plt.savefig('knn-1.jpg', dpi=120)\n",
        "\n",
        "plt.close()\n",
        "\n",
        "\n",
        "\n",
        "# 3b) Plot 2: Mean accuracy with error bars (±1 std), mark best k (save as knn2-1.jpg)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.errorbar(list(k_range), mean_accuracies, yerr=std_accuracies,\n",
        "\n",
        "             fmt='-o', ecolor='lightgray', capsize=5)\n",
        "\n",
        "plt.title('Value of K for KNN vs Cross-Validated Accuracy (with Std Dev)')\n",
        "\n",
        "plt.xlabel('Value of K for KNN')\n",
        "\n",
        "plt.ylabel('Cross-Validated Accuracy')\n",
        "\n",
        "plt.axvline(best_k_manual, color='red', linestyle='--', label=f'Best k={best_k_manual}')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.grid(True)\n",
        "\n",
        "plt.savefig('knn2-1.jpg', dpi=120)\n",
        "\n",
        "plt.close()\n",
        "\n",
        "\n",
        "\n",
        "# 4) GridSearchCV to confirm k=13 has the optimal parameter (with cv=10)\n",
        "\n",
        "param_grid = {'n_neighbors': list(k_range)}\n",
        "\n",
        "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10, scoring='accuracy')\n",
        "\n",
        "grid.fit(X, y)\n",
        "\n",
        "\n",
        "\n",
        "best_k_grid = grid.best_params_['n_neighbors']\n",
        "\n",
        "best_acc_grid = grid.best_score_\n",
        "\n",
        "\n",
        "\n",
        "print(f\"GridSearchCV: Best k = {best_k_grid}, Mean CV Accuracy = {best_acc_grid:.4f}\")\n",
        "\n",
        "print(f\"Do they match? {'Yes' if best_k_manual == best_k_grid else 'No'}\")\n",
        "\n",
        "\n",
        "\n",
        "# Optional: assert that GridSearchCV confirms k=13 specifically\n",
        "\n",
        "if best_k_grid != 13:\n",
        "\n",
        "    print(\"Note: With unshuffled cv=10, the optimal k may differ depending on folds. \"\n",
        "\n",
        "          \"Your book’s shuffled KFold found k=11; here we confirm the best k under cv=10.\")\n",
        "\n",
        "else:\n",
        "\n",
        "    print(\"Confirmed: k=13 is the optimal parameter with cv=10.\")\n",
        ""
      ]
    }
  ]
}